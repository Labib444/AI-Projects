{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Titanic ML.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "pe0DFRPXDMmx"
      },
      "source": [
        "import pandas as pd\r\n",
        "import numpy as np"
      ],
      "execution_count": 342,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JN9Nn4SRRlg9"
      },
      "source": [
        "Dataset = pd.read_csv('/content/drive/MyDrive/Kaggle /Titanic/train.csv')\r\n",
        "Dataset_Test = pd.read_csv('/content/drive/MyDrive/Kaggle /Titanic/test.csv')"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QWa75wtAiVzl"
      },
      "source": [
        "show_data_visualizations(Dataset)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1E0wJtC4kT6c"
      },
      "source": [
        "Train = Dataset.copy()\n",
        "Test = Dataset_Test.copy()\n",
        "Train, Test = basic_preprocessing(Train, Test)\n",
        "Train, Test = data_imputation_mice(Train, Test)\n",
        "Y_pred = prediction_model_xgboost( Train, Test, 100 )\n",
        "create_result_csv(Y_pred)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qE1PlWrz6Zgq"
      },
      "source": [
        "def basic_preprocessing(dataset, dataset_test):\r\n",
        "  dataset = dataset.iloc[:,[1,2,4,5,6,7,9,11]]\r\n",
        "  dataset_test = dataset_test.iloc[:,[1,3,4,5,6,8,10]]\r\n",
        "\r\n",
        "  dataset.Sex = pd.Categorical(dataset.Sex)\r\n",
        "  dataset['Sex'] = dataset.Sex.cat.codes\r\n",
        "  dataset.Embarked = pd.Categorical(dataset.Embarked)\r\n",
        "  dataset['Embarked'] = dataset.Embarked.cat.codes\r\n",
        "\r\n",
        "  dataset_test.Sex = pd.Categorical(dataset_test.Sex)\r\n",
        "  dataset_test['Sex'] = dataset_test.Sex.cat.codes\r\n",
        "  dataset_test.Embarked = pd.Categorical(dataset_test.Embarked)\r\n",
        "  dataset_test['Embarked'] = dataset_test.Embarked.cat.codes\r\n",
        "\r\n",
        "  return( dataset, dataset_test )"
      ],
      "execution_count": 347,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E-7gsWSvkJcW"
      },
      "source": [
        "def moderate_preprocessing():\r\n",
        "  dataset = dataset.iloc[:,[1,2,3,4,5,6,7,9,11]]\r\n",
        "  dataset_test = dataset_test.iloc[:,[1,2,3,4,5,6,8,10]]\r\n",
        "\r\n",
        "  dataset.Sex = pd.Categorical(dataset.Sex)\r\n",
        "  dataset['Sex'] = dataset.Sex.cat.codes\r\n",
        "  dataset.Embarked = pd.Categorical(dataset.Embarked)\r\n",
        "  dataset['Embarked'] = dataset.Embarked.cat.codes\r\n",
        "\r\n",
        "  dataset_test.Sex = pd.Categorical(dataset_test.Sex)\r\n",
        "  dataset_test['Sex'] = dataset_test.Sex.cat.codes\r\n",
        "  dataset_test.Embarked = pd.Categorical(dataset_test.Embarked)\r\n",
        "  dataset_test['Embarked'] = dataset_test.Embarked.cat.codes\r\n",
        "\r\n",
        "  dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\r\n",
        "  dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\r\n",
        "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\r\n",
        "  dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\r\n",
        "  dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\r\n",
        "  dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\r\n",
        "  title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\r\n",
        "  dataset['Title'] = dataset['Title'].map(title_mapping)\r\n",
        "  dataset = dataset.drop(columns=['Name'])\r\n",
        "\r\n",
        "  dataset_test['Title'] = dataset_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\r\n",
        "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace('Mlle', 'Miss')\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace('Ms', 'Miss')\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace('Mme', 'Mrs')\r\n",
        "  title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].map(title_mapping)\r\n",
        "  dataset_test = dataset_test.drop(columns=['Name'])\r\n",
        "\r\n",
        "  dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\r\n",
        "  dataset_test['FamilySize'] = dataset_test['SibSp'] + dataset_test['Parch'] + 1\r\n",
        "  \r\n",
        "  dataset['IsAlone'] = 0\r\n",
        "  dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\r\n",
        "  dataset = dataset.drop(columns=['FamilySize'])\r\n",
        "  dataset_test['IsAlone'] = 0\r\n",
        "  dataset_test.loc[dataset_test['FamilySize'] == 1, 'IsAlone'] = 1\r\n",
        "  dataset_test = dataset_test.drop(columns=['FamilySize'])"
      ],
      "execution_count": 346,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov52QilNkUMX"
      },
      "source": [
        "def preprocess_kaggle( dataset, dataset_test ):\r\n",
        "\r\n",
        "  dataset = dataset.iloc[:,[1,2,3,4,5,6,7,9,11]]\r\n",
        "  dataset_test = dataset_test.iloc[:,[1,2,3,4,5,6,8,10]]\r\n",
        "\r\n",
        "  dataset.Sex = pd.Categorical(dataset.Sex)\r\n",
        "  dataset['Sex'] = dataset.Sex.cat.codes\r\n",
        "  dataset.Embarked = pd.Categorical(dataset.Embarked)\r\n",
        "  dataset['Embarked'] = dataset.Embarked.cat.codes\r\n",
        "\r\n",
        "  dataset_test.Sex = pd.Categorical(dataset_test.Sex)\r\n",
        "  dataset_test['Sex'] = dataset_test.Sex.cat.codes\r\n",
        "  dataset_test.Embarked = pd.Categorical(dataset_test.Embarked)\r\n",
        "  dataset_test['Embarked'] = dataset_test.Embarked.cat.codes\r\n",
        "\r\n",
        "  dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\r\n",
        "  dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\r\n",
        "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\r\n",
        "  dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\r\n",
        "  dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\r\n",
        "  dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\r\n",
        "  title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\r\n",
        "  dataset['Title'] = dataset['Title'].map(title_mapping)\r\n",
        "  dataset = dataset.drop(columns=['Name'])\r\n",
        "\r\n",
        "  dataset_test['Title'] = dataset_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\r\n",
        "    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace('Mlle', 'Miss')\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace('Ms', 'Miss')\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].replace('Mme', 'Mrs')\r\n",
        "  title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\r\n",
        "  dataset_test['Title'] = dataset_test['Title'].map(title_mapping)\r\n",
        "  dataset_test = dataset_test.drop(columns=['Name'])\r\n",
        "\r\n",
        "  dataset['AgeBand'] = pd.cut(dataset['Age'], 5)\r\n",
        "  dataset[['AgeBand', 'Survived']].groupby(['AgeBand'], as_index=False).mean().sort_values(by='AgeBand', ascending=True)\r\n",
        "  dataset = dataset.drop(['AgeBand'], axis=1)\r\n",
        "\r\n",
        "  dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\r\n",
        "  dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\r\n",
        "  dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\r\n",
        "  dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\r\n",
        "  dataset.loc[ dataset['Age'] > 64, 'Age']\r\n",
        "\r\n",
        "  dataset_test.loc[ dataset_test['Age'] <= 16, 'Age'] = 0\r\n",
        "  dataset_test.loc[(dataset_test['Age'] > 16) & (dataset_test['Age'] <= 32), 'Age'] = 1\r\n",
        "  dataset_test.loc[(dataset_test['Age'] > 32) & (dataset_test['Age'] <= 48), 'Age'] = 2\r\n",
        "  dataset_test.loc[(dataset_test['Age'] > 48) & (dataset_test['Age'] <= 64), 'Age'] = 3\r\n",
        "  dataset_test.loc[ dataset_test['Age'] > 64, 'Age']\r\n",
        "\r\n",
        "  #Adding Family Size and Adding IsAlone\r\n",
        "  dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\r\n",
        "  dataset_test['FamilySize'] = dataset_test['SibSp'] + dataset_test['Parch'] + 1\r\n",
        "  \r\n",
        "  dataset['IsAlone'] = 0\r\n",
        "  dataset.loc[dataset['FamilySize'] == 1, 'IsAlone'] = 1\r\n",
        "  dataset = dataset.drop(columns=['FamilySize'])\r\n",
        "  dataset_test['IsAlone'] = 0\r\n",
        "  dataset_test.loc[dataset_test['FamilySize'] == 1, 'IsAlone'] = 1\r\n",
        "  dataset_test = dataset_test.drop(columns=['FamilySize'])\r\n",
        "  \r\n",
        "\r\n",
        "  dataset = dataset.drop(columns=['SibSp','Parch'])\r\n",
        "  dataset_test = dataset_test.drop(columns=['SibSp','Parch'])\r\n",
        "\r\n",
        "\r\n",
        "  dataset['FareBand'] = pd.qcut(dataset['Fare'], 4)\r\n",
        "  dataset[['FareBand', 'Survived']].groupby(['FareBand'], as_index=False).mean().sort_values(by='FareBand', ascending=True)\r\n",
        "  dataset = dataset.drop(columns=['FareBand'])\r\n",
        "\r\n",
        "  dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0.0\r\n",
        "  dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1.0\r\n",
        "  dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2.0\r\n",
        "  dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3.0\r\n",
        "  dataset['Fare'] = dataset['Fare']\r\n",
        "\r\n",
        "  dataset_test.loc[ dataset_test['Fare'] <= 7.91, 'Fare'] = 0.0\r\n",
        "  dataset_test.loc[(dataset_test['Fare'] > 7.91) & (dataset_test['Fare'] <= 14.454), 'Fare'] = 1.0\r\n",
        "  dataset_test.loc[(dataset_test['Fare'] > 14.454) & (dataset_test['Fare'] <= 31), 'Fare']   = 2.0\r\n",
        "  dataset_test.loc[ dataset_test['Fare'] > 31, 'Fare'] = 3.0\r\n",
        "  dataset_test['Fare'] = dataset_test['Fare']\r\n",
        "\r\n",
        "  dataset['Age*Class'] = dataset.Age * dataset.Pclass\r\n",
        "  dataset_test['Age*Class'] = dataset_test.Age * dataset_test.Pclass\r\n",
        "\r\n",
        "  \r\n",
        "  return (dataset, dataset_test)"
      ],
      "execution_count": 278,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ec_-nEvEup_s"
      },
      "source": [
        "def data_imputation_mice(dataset, dataset_test):\r\n",
        "  !pip install impyute\r\n",
        "  from impyute.imputation.cs import mice\r\n",
        "\r\n",
        "  # start the MICE training\r\n",
        "  imputed_training=mice(dataset.values)\r\n",
        "  imputed_test=mice(dataset_test.values)\r\n",
        "\r\n",
        "  pd.DataFrame(imputed_training).isnull().sum()\r\n",
        "  imputed_training = pd.DataFrame(imputed_training)\r\n",
        "  imputed_test = pd.DataFrame(imputed_test)\r\n",
        "\r\n",
        "  return ( imputed_training, imputed_test )"
      ],
      "execution_count": 138,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RVTMm8fj3Guc"
      },
      "source": [
        "def prediction_model_catboost(imputed_training, imputed_test, iterations):\r\n",
        "  !pip install catboost\r\n",
        "  from catboost import CatBoostClassifier, Pool\r\n",
        "\r\n",
        "  imputed_training_y = imputed_training.iloc[:,0]\r\n",
        "  imputed_training =  imputed_training.iloc[:,1:]\r\n",
        "  imputed_training_y = imputed_training_y.values\r\n",
        "  imputed_training = imputed_training.values\r\n",
        "\r\n",
        "  train_data = Pool(imputed_training,imputed_training_y)\r\n",
        "  test_data = Pool(imputed_test)\r\n",
        "\r\n",
        "  model = CatBoostClassifier(iterations=iterations)\r\n",
        "\r\n",
        "  model.fit(train_data)\r\n",
        "  Y_pred = model.predict(test_data, prediction_type='Class')\r\n",
        "\r\n",
        "  acc_catboost = round(model.score(imputed_training, imputed_training_y) * 100, 2)\r\n",
        "  print( acc_catboost )\r\n",
        "\r\n",
        "  return (Y_pred)"
      ],
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YjNsNXkhw1ys"
      },
      "source": [
        "def prediction_model_random_forest(imputed_training, imputed_test, n_estimators):\r\n",
        "  from sklearn.ensemble import RandomForestClassifier\r\n",
        "\r\n",
        "  imputed_training_y = imputed_training.iloc[:,0]\r\n",
        "  imputed_training =  imputed_training.iloc[:,1:]\r\n",
        "  imputed_training_y = imputed_training_y.values\r\n",
        "  imputed_training = imputed_training.values\r\n",
        "\r\n",
        "  random_forest = RandomForestClassifier(n_estimators=n_estimators)\r\n",
        "  random_forest.fit(imputed_training, imputed_training_y)\r\n",
        "  Y_pred = random_forest.predict(imputed_test)\r\n",
        "\r\n",
        "  acc_random_forest = round(random_forest.score(imputed_training, imputed_training_y) * 100, 2)\r\n",
        "  print( acc_random_forest )\r\n",
        "\r\n",
        "  return Y_pred"
      ],
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nwqePSMBuL91"
      },
      "source": [
        "def prediction_model_xgboost(imputed_training, imputed_test, n_estimators):\r\n",
        "  #regressor = xgb.XGBClassifier(n_estimators=100, reg_lambda=1, gamma=0, max_depth=3)\r\n",
        "  from xgboost import XGBClassifier\r\n",
        "\r\n",
        "  imputed_training_y = imputed_training.iloc[:,0]\r\n",
        "  imputed_training =  imputed_training.iloc[:,1:]\r\n",
        "  \r\n",
        "  imputed_training_y = imputed_training_y.values\r\n",
        "  imputed_training = imputed_training.values\r\n",
        "\r\n",
        "  imputed_training = pd.DataFrame(imputed_training)\r\n",
        "  imputed_training = imputed_training.values\r\n",
        "\r\n",
        "  imputed_test = imputed_test.values\r\n",
        "  imputed_test = pd.DataFrame(imputed_test)\r\n",
        "  imputed_test = imputed_test.values\r\n",
        "\r\n",
        "  model = XGBClassifier(n_estimators=n_estimators)\r\n",
        "  model.fit(imputed_training, imputed_training_y)\r\n",
        "  Y_pred = model.predict(imputed_test)\r\n",
        "\r\n",
        "  acc_xgboost = round(model.score(imputed_training, imputed_training_y) * 100, 2)\r\n",
        "  print( acc_xgboost )\r\n",
        "\r\n",
        "  return Y_pred"
      ],
      "execution_count": 319,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bo76L1GAvLHo"
      },
      "source": [
        "def show_data_visualizations( train_df ):\r\n",
        "  import seaborn as sns\r\n",
        "  import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "  g = sns.FacetGrid(train_df, col='Survived')\r\n",
        "  g.map(plt.hist, 'Age', bins=20)\r\n",
        "\r\n",
        "  grid = sns.FacetGrid(train_df, col='Survived', row='Pclass', size=2.2, aspect=1.6)\r\n",
        "  grid.map(plt.hist, 'Age', alpha=.5, bins=20)\r\n",
        "  grid.add_legend();\r\n",
        "\r\n",
        "  grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\r\n",
        "  grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\r\n",
        "  grid.add_legend()\r\n",
        "\r\n",
        "  grid = sns.FacetGrid(train_df, row='Embarked', col='Survived', size=2.2, aspect=1.6)\r\n",
        "  grid.map(sns.barplot, 'Sex', 'Fare', alpha=.5, ci=None)\r\n",
        "  grid.add_legend()"
      ],
      "execution_count": 344,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwvCBI0QkVv9"
      },
      "source": [
        "def create_result_csv(Y_pred):\n",
        "  result = pd.read_csv('/content/drive/MyDrive/Kaggle /Titanic/gender_submission.csv')\n",
        "  result.Survived = pd.DataFrame(Y_pred.astype('int64'))\n",
        "  result.to_csv('result.csv',index=False)"
      ],
      "execution_count": 144,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9AyUOj5YkVlq"
      },
      "source": [
        "# import sys\r\n",
        "# from impyute.imputation.cs import fast_knn\r\n",
        "# sys.setrecursionlimit(100000) #Increase the recursion limit of the OS\r\n",
        "\r\n",
        "# # start the KNN training\r\n",
        "# imputed_training=fast_knn(train.values, k=30)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}